# -*- coding: utf-8 -*-
"""updatedCAD(PredictionModel).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YEdxpdnh9J1X8aF8ef2jyZ3efLl5kxXa

## Import required Libraries
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import pickle

"""## Load Dataset"""

data_0 = pd.read_excel('data/Coronary_artery.xlsx')

"""## Explore Dataset"""

data_0.head()

data_0.shape

data_0.info

data_0.isnull().sum()

data_0.groupby(['class']).sum()

"""## Data processing"""

# Encode categorical variables
le = LabelEncoder()
data_0['sex'] = le.fit_transform(data_0['sex'])
data_0['cp'] = le.fit_transform(data_0['cp'])
data_0['fbs'] = le.fit_transform(data_0['fbs'])
data_0['restecg'] = le.fit_transform(data_0['restecg'])
data_0['exang'] = le.fit_transform(data_0['exang'])
data_0['slope'] = le.fit_transform(data_0['slope'])
data_0['thal'] = le.fit_transform(data_0['thal'])

data_0

data_0.describe()

data_0.corr()

plt.boxplot([data_0['trestbps']])
plt.show

# # from pandas.core.internals import concat
# count = data_0['class'].value_counts()
# prec = data_0['class'].value_counts(normalize =True)
# concat([count, prec], axis =1, keys = ["Count", "Percentage"])
from collections import Counter
print(Counter(data_0["class"]))

"""## Split Dataset into training and test dataset"""

feature_cols = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',
                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']
X = data_0[feature_cols]
y= data_0['class']

# example of random oversampling to balance the class distribution
from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import RandomOverSampler
# summarize class distribution
print(Counter(y))
# define oversampling strategy
oversample = RandomOverSampler(sampling_strategy='minority')
# fit and apply the transform
X_over, y_over = oversample.fit_resample(X, y)
# summarize class distribution
print(Counter(y_over))

X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state = 42)

"""## Standardise the input Data"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_test

"""## Model Training"""

svm_model = SVC(kernel='rbf', C=5)
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)
print(y_pred)
# print(X_test)

"""## Model Evaluation"""

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

"""## Performance Evaluation"""

print(f'Accuracy: {accuracy*100}')

print('Confusion Matrix:')
print(conf_matrix)

print('Classification Report:')
print(class_report)

# Saving model to disk
pickle.dump(svm_model, open('modelCAD.pkl','wb'))
pickle.dump(scaler, open('scalerCAD.pkl','wb'))

# Loading model to compare the results
modelCAD = pickle.load(open('modelCAD.pkl','rb'))
input_val = scaler.transform([[67, 1, 0, 160, 286, 0, 1, 108, 1, 1.5, 1, 3, 1]])
print(modelCAD.predict(input_val))
